{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ra0dyk1rK7UO"
   },
   "source": [
    "# Budowa modelu sieci konwolucyjnych do rozpoznawania obrazów ze zbioru CIFAR100\n",
    "\n",
    "\n",
    "\n",
    "### Opis zbioru danych:\n",
    "\n",
    "\n",
    "\n",
    "CIFAR100 (Canadian Institute For Advanced Research) jest popularnym zbiorem benchmarkowym, wykorzystywanym do nauki i oceny algorytmów uczenia maszynowego oraz rozpoznawania obrazów. Jest to bardziej rozbudowana wersja zbioru CIFAR10, posiada 100 klas obrazów, czyli 10 razy więcej niż poprzednik. Każda z klas zawiera 600 kolorowych obrazów o wymiarze 32x32 pikseli, łacznie znajdziemy ich 60000 w całym zestawie.\n",
    "\n",
    "\n",
    "\n",
    "#### CIFAR100 został pogrupowany na odpowiednie superklasy oraz klasy:\n",
    "\n",
    "\n",
    "\n",
    "|Superclasses | Classes|\n",
    "|- |- |\n",
    "|aquatic mammals| beaver, dolphin, otter, seal, whale|\n",
    "|fish| aquarium fish, flatfish, ray, shark, trout|\n",
    "|flowers| orchids, poppies, roses, sunflowers, tulips|\n",
    "|food containers| bottles, bowls, cans, cups, plates|\n",
    "|fruit and vegetables| apples, mushrooms, oranges, pears, sweet peppers|\n",
    "|household electrical devices| clock, computer keyboard, lamp, telephone, television|\n",
    "|household furniture| bed, chair, couch, table, wardrobe|\n",
    "|insects| bee, beetle, butterfly, caterpillar, cockroach|\n",
    "|large carnivores| bear, leopard, lion, tiger, wolf|\n",
    "|large man-made outdoor things| bridge, castle, house, road, skyscraper|\n",
    "|large natural outdoor scenes| cloud, forest, mountain, plain, sea|\n",
    "|large omnivores and herbivores| camel, cattle, chimpanzee, elephant, kangaroo|\n",
    "|medium-sized mammals| fox, porcupine, possum, raccoon, skunk|\n",
    "|non-insect invertebrates| crab, lobster, snail, spider, worm|\n",
    "|people| baby, boy, girl, man, woman|\n",
    "|reptiles| crocodile, dinosaur, lizard, snake, turtle|\n",
    "|small mammals| hamster, mouse, rabbit, shrew, squirrel|\n",
    "|trees| maple, oak, palm, pine, willow|\n",
    "|vehicles 1| bicycle, bus, motorcycle, pickup truck, train|\n",
    "|vehicles 2| lawn-mower, rocket, streetcar, tank, tractor|\n",
    "\n",
    "\n",
    "\n",
    "\"Yes, I know mushrooms aren't really fruit or vegetables and bears aren't really carnivores.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fDa1sqN3ckM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Activation, MaxPool2D, Flatten, Dropout, BatchNormalization, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qf9iIpICT53J"
   },
   "source": [
    "#### Załadowanie zbioru danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Miymh0zh4PvT",
    "outputId": "b8fd9702-bd22-46e4-b549-4e7674c696f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#dataset loading\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKqVuG6TSmUl"
   },
   "source": [
    "#### Po załadowaniu danych pierwszą czynnością było sprawdzenie wymiarowości danych – liczby pikseli na zdjęciach i kanałów RGB i zapisanie jako wymiary wejściowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJZDR2op4txp"
   },
   "outputs": [],
   "source": [
    "#data shape\n",
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YL3SbnDmS1u6"
   },
   "source": [
    "### Następnie ustawione zostało kilka parametrów\n",
    "- Sprawdzona została liczba klas, aby upewnić się czy model został prawidłowo wgrany.\n",
    "- Ustawione zostało ziarno losowe na poziomie 1234, aby otrzymywać powtarzalność wyników\n",
    "- Przyjętę zostało 100 epok z użyciem Early Stopping sprawdzającym co 10 epok (wytłumaczone w dalszej części raportu)\n",
    "- Batch size na poziomie 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7BqRdXt42mv"
   },
   "outputs": [],
   "source": [
    "# number of classes\n",
    "classes = len(np.unique(y_train))\n",
    "random_state = 1234\n",
    "epochs = 100\n",
    "Batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJboIKnsTfdM"
   },
   "source": [
    "#### W tej części dokonana została standaryzacja danych celem zmniejszenia odległości pomiędzy tensorami w sieci, co w większości przypadków jest zalecane i powoduje zwiększenie wyników."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qXAItPB6w_6"
   },
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsEMq4f4Tiv_"
   },
   "source": [
    "#### Tu dokonana została zmiana struktury macierzy danych wynikowych. W pierwotnej wersji sieć nie mogła zweryfikować swojej istotności, ponieważ dane wynikowe zawierały tylko jedną kolumnę z wynikiem od 0 do 100, w czasie gdy sieć zwracała wyniki w formie macierzy zawierającej 100 kolumn. Poniższy kod zmieniał wymiarowość macierzy, doprowadzając je do tego samego formatu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rn-mf0Y7IWHz"
   },
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=100)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S14BxZCRToP9"
   },
   "source": [
    "### Data augmentation Po polsku rozszerzanie danych - to technika służąca do zwiększania ilości danych poprzez dodawanie nieznacznie zmodyfikowanych kopii już istniejących danych lub nowo utworzonych danych syntetycznych z istniejących danych. Działa jak regularyzator i pomaga zmniejszyć nadmierne dopasowanie podczas szkolenia modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sn9s5pBNj138"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSQjEb_VMhtG"
   },
   "source": [
    "## Model sieci konwolucyjnej\n",
    "><b>Do rozwiązania problemu posłużono się siecią konwolucyjnymi</b>, ponieważ ze względu na ich umiejętność stopniowego filtrowania różnych części danych uczących oraz wyostrzania ważnych cech świetnie sprawdzają się one w procesie rozpoznawania obrazów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-92MlC-Mw3T"
   },
   "source": [
    "### Opis architektury sieci konwolucyjnych\n",
    "> <b>Deep learning pozwala modelom obliczeniowym wielu warstw przetwarzania, nauczyć się i reprezentować dane z wieloma poziomami abstrakcji</b> naśladując, w jaki sposób mózg odbiera i rozumie informacje multimodalne, a więc przechwytuje skomplikowane struktury danych na dużą skalę. Konwolucyjne sieci neuronowe są oparte na algorytmie głębokiego uczenia. Wykorzystuje się je w celu przetwarzania danych, które składają się z wielowymiarowych macierzy. Przykładem takich macierzy są obrazy, dlatego sieci te sprawdzają się dobrze w przetwarzania obrazów.\n",
    "<br><br> <b>Architektura sieci konwolucyjnych</b> wykorzystuje trzy konkretne pomysły:  lokalne pola receptywne,  powiązane obciążeń i podpróbkowanie przestrzenne. W oparciu o lokalne pole receptywne, każda jednostka w warstwie splotowej otrzymuje dane wejściowe z zestawu sąsiednich jednostek należących do poprzedniej warstwy. W ten sposób neurony są w stanie wyodrębnić elementarne części wizualne, takie jak krawędzie lub rogi. Funkcje te są następnie łączone przez kolejne warstwy splotowe w celu wykrycia cech wyższego rzędu. Ponadto idea, że elementarne detektory cech, które są użyteczne na części obrazu, mogą być użyteczne w całym obrazie, jest realizowana przez koncepcję wiązania obciążeń. Pojęcie wiązanych obciążeń ogranicza zestaw jednostek, aby miały identyczne wagi.\n",
    "<br><br> Podstawą konstrukcji sieci konwolucyjnej są <b>warstwy</b> przyjęte w ilości i rozmiarze, który zależy od stopnia złożoności zadania rozpoznawania. Z uwagi na charakter danych wejściowych (dane obrazowe) oraz stosowane współcześnie metody uczenia, powszechne jest stosowanie warstw. <b>Warstwa wejściowa</b> jest zdefiniowana rozmiarami obrazów poddawanych przetwarzaniu i otrzymuje surowe wartości ich pikseli, które w procesie uczenia są eksponowane wraz z informacją o przynależności do klas. Wymiar warstwy to wysokość i szerokość obrazów wejściowych, które w ramach wstępnego przetwarzania muszą być ujednolicone. <b>Warstwę konwolucyjną</b> tworzy pewna liczba zbiorów neuronów. Wejścia każdego z neuronów połączone są z pewną liczbą pikseli obrazu wejściowego tworzących lokalne, prostokątne pola recepcyjne o zadanych wymiarach lub z pewną liczbą elementów warstwy poprzedzającej, jeśli sieć posiada kilka warstw konwolucyjnych. Dla każdego ze zbiorów neuronów na etapie uczenia wyznaczane są <b>wagi</b>, przy czym każdy z neuronów należących do określonego zbioru ma te wagi jednakowe. Przetwarzanie obrazu przez nauczoną warstwę konwolucyjną może być więc ekwiwalentnie zastąpione jego filtracją zrealizowaną za pomocą splotu (konwolucji) z wykorzystaniem neuronów-filtrów o ustalonych wagach-współczynnikach. Zbiór wszystkich powstałych w wyniku splatania obrazów tworzy mapy cech.\n",
    "<br><br>Operację łączenia wielu wyników pochodzących z sąsiedztwa w mapach cech w jedną cechę realizuje warstwa redukująca tzw. <b>warstwa poolingu</b>. Warstwa ta realizuje filtrację statystyczną w obrębie maski o zadanych rozmiarach wyznaczając wybraną statystykę, np. wartość maksymalną, minimalną lub średnią. Maski przetwarzające obraz w ten sposób nie pokrywają się. W warstwie tej nie występuje proces uczenia, ale dzięki możliwości wybrania odpowiednio dużego kroku przy przesuwaniu maski otrzymuje się redukcję wymiarów map cech (pomniejszone mapy cech), co sprzyja poprawie szybkości uczenia. Poza tym, w przypadku stosowania po niej kolejnej warstwy konwolucyjnej, warstwa redukująca daje jej neuronom możliwość objęcia większej powierzchni obrazu i tym samym kształtowanie innych rodzajów cech. Sieć uzyskuje również pewną odporność na przesunięcia wzorców obrazów. Warstwa ta tym samym ogranicza również ryzyko przetrenowania.\n",
    "<br><br> <b>Do budowy sieci wybrano warstwę poolingu typu max, która jest najpopularniejszym rodzajem warstwy łączącej. Dalsze decyzje doboru hiperparametrów przedstawiono w dalszej części pracy. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rya6CSb_NcJG"
   },
   "source": [
    "### Funkcje aktywacji\n",
    ">Rolą funkcji aktywacji jest przedstawienie, w jakim stopniu dany neuron jest pobudzony aktualnie docierającymi do niego wartościami.\n",
    "Wynik działania warstwy konwolucyjnej może zawierać wartości ujemne, które są eliminowane przez nieliniową <b>funkcję aktywacji o nazwie ReLU (ang. rectified linear unit)</b>. Funkcja ta wartości pikseli, które w mapach cech są dodatnie pozostawia bez zmian a ujemne zamienia na zerowe. Funkcja ReLU jest nieco szybsza od pozostałych funkcji aktywacji, a ponadto algorytm spadku gradientowego rzadziej zatrzymuje się na wypłaszczeniach ze względu na większą odporność na duże wartości wejściowe. Funkcja logistyczna i tangensa hiperbolicznego sprawdzają się nieco gorzej, gdyż ulegają nasyceniu w punkcie 1, por. Geron (2017). <b> Ze względu na powyższe w pracy posłużono się funkcją ReLU. </b><br><br>\n",
    "<b>W przypadku warstwy wyjściowej pojedynczą funkcję aktywacji zastąpiono współdzieloną funkcją typu softmax</b>, która dla każdej obserwacji oblicza prawdopodobieństwo przynależności obrazu wejściowego do określonej kategorii. Funkcja ta jest odpowiednia do przedstawionego problemu ze względu na wzajemnie wykluczające się klasy zdjęć."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqIj0PHTNkxl"
   },
   "source": [
    "### Algorytm optymalizacji\n",
    "\n",
    "> Algorytmy optymalizacji pomagają zminimalizować (lub zmaksymalizować) funkcję straty, która jest zależna od wewnętrznych parametrów uczenia się modelu oraz która jest używana do obliczania wartości docelowych na podstawie zestawu predyktorów. W praktyce oznacza to, że wagi i odchylenia są wykorzystywane do obliczenia wartości wyjściowych i aktualizowane tak, aby dążyć w kierunku optymalnego rozwiązania.\n",
    "Jednym z przykładowych algorytmów optymalizujących jest ADAM\n",
    "- <B>ADAM</B> (Adaptive Moment Estimation) - działa dobrze w praktyce i wypada korzystnie w porównaniu z innymi algorytmami adaptacyjnej metody uczenia się, ponieważ zbiega bardzo szybko, a szybkość uczenia się modelu przebiega równie sprawnie i efektywnie.  Dodatkowo naprawia problemy spotykane w innych technikach optymalizacji takie jak: zanikająca stopa uczenia, powolne osiąganie kryterium zbiezności lub wysoka wariancja w aktualizowaniu parametrów co prowadzi do wahań w funkcji straty.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRr_3HuwOX6h"
   },
   "source": [
    "### Przeuczenie i regularyzacja\n",
    "Elastyczność związana z ogromną liczbą parametrów sieci neuronowych związana jest z podatnością na ich <b>przetrenowanie</b>. Wśród technik regularyzacji wyróżnić można: wczesne <b>zatrzymywanie, modyfikacje funkcji kosztu, porzucanie (dropout), regularyzacja typu max-norm oraz dogenerowanie danych z istniejących przykładów</b>.  \n",
    "<br><b>W pracy do budowy modeli sieci konwolucyjnej posłużono się metodą wczesnego zatrzymywania</b> polegającą na przerwaniu procesu uczenia sieci w momencie spadku wydajnośći modelu wobec zbioru walidacyjnego. Zaimplementowano tę metodę poprzez ocenianie wydajności modelu w regularnych odstępach czasu i ocenę wielkości błędu na poszczególnych zbiorach na wykresie.\n",
    "W miarę upływu kolejnych epok procesu uczenia algorytm uczy się, a więc błąd predycji spada, a rośnie dokładność na zestawie uczącym. Jeśli jednak błąd na danych walidacyjnych zaczyna rosnąć, oznacza to, że model ulega przetrenowaniu. Wczesne zatrzymanie umożliwia przerwanie procesu w momencie osiągnięcia minimalnej wartości błędu predykcji.\n",
    "<b>Posłużono się również techniką regularyzacji dropout </b>\n",
    "Jest to najpopularniejsza z technik regularyzacji zaproponowana przez G. E. Hintona w 2012 roku. Istnieje wiele prac dowodzących skuteczności tej metody - nawet najbardziej złożone sieci neuronowe uzyskują 1-2% poprawę precyzji przez zastosowanie dropoutu. Idea algorytmu opiera się na prostym założeniu: w procesie uczenia z każdym krokiem każdy neuron z wyjątkiem tych z warstwy wyjściowej posiada prawdopodobieństwo <i>p</i> bycia porzuconym ze zbioru w tym kroku. Hiperparametr <i>p</i> zazwyczaj przyjmuje poziom 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seXq0-U3N_mS"
   },
   "source": [
    "### Budowa modelu\n",
    "> <b> W procedurze budowy najlepszego modelu trenowano wiele różnych sieci. W pracy zaprezentowano jedynie model dwa modele sieci konwolucyjnej - o mniej oraz bardziej skomplikowanej architekturze. Model finalny okazał się być modelem najlepszym, a poprzedzający posłużył w pracy jako benchmark, został zoptymalizowany za pomocą funkcji dropout, dodaniem warstwy Maxpooling i funkcji BatchNormalization, model finalny osiągnął znacznie lepszy wynik na zbiorze testowy co świadczy o tym, że dodanie tych funcji pozwoliło na zmniejszenie przeuczenia modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRE2V3Wf6_3D"
   },
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBAknyBP6_AG"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=10, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                  kernel_initializer='he_normal',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(Dense(classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uH4B6RJCE6nK"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss= losses.CategoricalCrossentropy(from_logits=True), metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DU_ZB4vVE6CA",
    "outputId": "0f5ca1fc-f340-4a8e-9eb3-ce4dbdcd420a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "391/391 [==============================] - 39s 98ms/step - loss: 4.5505 - accuracy: 0.0343 - val_loss: 3.8593 - val_accuracy: 0.0998\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 39s 100ms/step - loss: 3.8149 - accuracy: 0.1075 - val_loss: 3.4844 - val_accuracy: 0.1624\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 3.5660 - accuracy: 0.1495 - val_loss: 3.3259 - val_accuracy: 0.1983\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 39s 100ms/step - loss: 3.3775 - accuracy: 0.1847 - val_loss: 3.1761 - val_accuracy: 0.2201\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 3.2336 - accuracy: 0.2097 - val_loss: 3.0283 - val_accuracy: 0.2467\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 3.1256 - accuracy: 0.2268 - val_loss: 2.9542 - val_accuracy: 0.2663\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 3.0213 - accuracy: 0.2480 - val_loss: 2.8580 - val_accuracy: 0.2859\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 2.9380 - accuracy: 0.2631 - val_loss: 2.7642 - val_accuracy: 0.3040\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 2.8718 - accuracy: 0.2788 - val_loss: 2.7082 - val_accuracy: 0.3177\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 2.7825 - accuracy: 0.2950 - val_loss: 2.6868 - val_accuracy: 0.3208\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 2.7087 - accuracy: 0.3077 - val_loss: 2.5659 - val_accuracy: 0.3464\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 2.6556 - accuracy: 0.3211 - val_loss: 2.5450 - val_accuracy: 0.3437\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 2.5847 - accuracy: 0.3326 - val_loss: 2.6194 - val_accuracy: 0.3424\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 2.5485 - accuracy: 0.3426 - val_loss: 2.4744 - val_accuracy: 0.3660\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 2.4749 - accuracy: 0.3621 - val_loss: 2.5189 - val_accuracy: 0.3588\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 2.4425 - accuracy: 0.3638 - val_loss: 2.4604 - val_accuracy: 0.3708\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 2.4106 - accuracy: 0.3702 - val_loss: 2.3699 - val_accuracy: 0.3879\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 2.3698 - accuracy: 0.3789 - val_loss: 2.5066 - val_accuracy: 0.3639\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 2.3274 - accuracy: 0.3903 - val_loss: 2.3126 - val_accuracy: 0.3977\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 2.3052 - accuracy: 0.3945 - val_loss: 2.3584 - val_accuracy: 0.3915\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 2.2732 - accuracy: 0.3975 - val_loss: 2.3036 - val_accuracy: 0.3972\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 2.2046 - accuracy: 0.4117 - val_loss: 2.2643 - val_accuracy: 0.4080\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 2.2040 - accuracy: 0.4107 - val_loss: 2.3533 - val_accuracy: 0.3954\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 2.1871 - accuracy: 0.4191 - val_loss: 2.3671 - val_accuracy: 0.3947\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 2.1750 - accuracy: 0.4185 - val_loss: 2.2560 - val_accuracy: 0.4141\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 2.1213 - accuracy: 0.4337 - val_loss: 2.1893 - val_accuracy: 0.4273\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 2.1059 - accuracy: 0.4348 - val_loss: 2.4141 - val_accuracy: 0.3912\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 2.0955 - accuracy: 0.4371 - val_loss: 2.3362 - val_accuracy: 0.3988\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 2.0672 - accuracy: 0.4438 - val_loss: 2.3490 - val_accuracy: 0.4056\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 2.0336 - accuracy: 0.4437 - val_loss: 2.2477 - val_accuracy: 0.4151\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 2.0336 - accuracy: 0.4495 - val_loss: 2.2423 - val_accuracy: 0.4186\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 2.0169 - accuracy: 0.4539 - val_loss: 2.1607 - val_accuracy: 0.4308\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 1.9827 - accuracy: 0.4610 - val_loss: 2.3014 - val_accuracy: 0.4172\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 1.9735 - accuracy: 0.4637 - val_loss: 2.2492 - val_accuracy: 0.4242\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 1.9773 - accuracy: 0.4638 - val_loss: 2.1530 - val_accuracy: 0.4417\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 1.9340 - accuracy: 0.4750 - val_loss: 2.2809 - val_accuracy: 0.4215\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 1.9383 - accuracy: 0.4698 - val_loss: 2.2006 - val_accuracy: 0.4322\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 1.9281 - accuracy: 0.4712 - val_loss: 2.1833 - val_accuracy: 0.4390\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 1.8970 - accuracy: 0.4821 - val_loss: 2.0936 - val_accuracy: 0.4537\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 1.9015 - accuracy: 0.4814 - val_loss: 2.1352 - val_accuracy: 0.4495\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 1.8860 - accuracy: 0.4827 - val_loss: 2.1884 - val_accuracy: 0.4352\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 1.8652 - accuracy: 0.4855 - val_loss: 2.1799 - val_accuracy: 0.4415\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 1.8340 - accuracy: 0.4936 - val_loss: 2.1527 - val_accuracy: 0.4466\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 1.8515 - accuracy: 0.4897 - val_loss: 2.2117 - val_accuracy: 0.4414\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 1.8381 - accuracy: 0.4957 - val_loss: 2.3331 - val_accuracy: 0.4261\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 1.8296 - accuracy: 0.4981 - val_loss: 2.1556 - val_accuracy: 0.4533\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 1.8095 - accuracy: 0.4997 - val_loss: 2.2255 - val_accuracy: 0.4363\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 1.8061 - accuracy: 0.5020 - val_loss: 2.1648 - val_accuracy: 0.4506\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 1.7992 - accuracy: 0.5037 - val_loss: 2.1997 - val_accuracy: 0.4487\n"
     ]
    }
   ],
   "source": [
    "train_model = model.fit(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                  epochs=epochs,\n",
    "                  callbacks=[early_stopping],\n",
    "                  verbose=1,\n",
    "                  validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2MU9DF1yFLUi",
    "outputId": "d94bbf19-60dc-42e4-8c1d-764de13a1272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 2.0936 - accuracy: 0.4537\n",
      "Test loss: 2.093562126159668\n",
      "Test accuracy: 0.4537000060081482\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, steps=math.ceil(10000/32))\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwXGK1UThHMH"
   },
   "source": [
    "Po pierwszym treningu modelu widać, że jest on trochę przeuczony i można go jeszcze usprawnić"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBh-kDjwhNGw"
   },
   "source": [
    "###Tuning modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZZpCX_2-LH3"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=10, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                  kernel_initializer='he_normal',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOynAyQo7W45"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss= losses.CategoricalCrossentropy(from_logits=True), metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-w4Turmd8ZGK",
    "outputId": "dde625d4-8eda-4f63-ec90-03c4b5a0775e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "391/391 [==============================] - 30s 74ms/step - loss: 4.6550 - accuracy: 0.0353 - val_loss: 4.3104 - val_accuracy: 0.0556\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 4.0315 - accuracy: 0.0772 - val_loss: 3.9333 - val_accuracy: 0.0940\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 3.8582 - accuracy: 0.1020 - val_loss: 3.9326 - val_accuracy: 0.1065\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 3.6796 - accuracy: 0.1286 - val_loss: 3.4137 - val_accuracy: 0.1767\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 3.5660 - accuracy: 0.1522 - val_loss: 3.1739 - val_accuracy: 0.2098\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 3.4511 - accuracy: 0.1665 - val_loss: 3.0001 - val_accuracy: 0.2526\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 3.3552 - accuracy: 0.1857 - val_loss: 3.0664 - val_accuracy: 0.2430\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 3.2608 - accuracy: 0.2052 - val_loss: 2.9205 - val_accuracy: 0.2628\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 3.1749 - accuracy: 0.2167 - val_loss: 2.8451 - val_accuracy: 0.2751\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 3.1075 - accuracy: 0.2279 - val_loss: 2.6625 - val_accuracy: 0.3078\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 3.0304 - accuracy: 0.2464 - val_loss: 2.7585 - val_accuracy: 0.2897\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 2.9799 - accuracy: 0.2533 - val_loss: 2.5476 - val_accuracy: 0.3366\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 2.9221 - accuracy: 0.2672 - val_loss: 2.5022 - val_accuracy: 0.3403\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 28s 73ms/step - loss: 2.8528 - accuracy: 0.2758 - val_loss: 2.5180 - val_accuracy: 0.3391\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.8115 - accuracy: 0.2890 - val_loss: 2.4686 - val_accuracy: 0.3566\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 2.7680 - accuracy: 0.2976 - val_loss: 2.3960 - val_accuracy: 0.3706\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.7164 - accuracy: 0.3105 - val_loss: 2.7476 - val_accuracy: 0.3181\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.6880 - accuracy: 0.3157 - val_loss: 2.3276 - val_accuracy: 0.3866\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.6203 - accuracy: 0.3306 - val_loss: 2.4293 - val_accuracy: 0.3876\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.6061 - accuracy: 0.3337 - val_loss: 2.3627 - val_accuracy: 0.3801\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 28s 73ms/step - loss: 2.5452 - accuracy: 0.3461 - val_loss: 2.1728 - val_accuracy: 0.4212\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.5149 - accuracy: 0.3532 - val_loss: 2.2208 - val_accuracy: 0.4196\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 28s 73ms/step - loss: 2.4690 - accuracy: 0.3594 - val_loss: 2.3072 - val_accuracy: 0.4091\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 28s 73ms/step - loss: 2.4429 - accuracy: 0.3654 - val_loss: 2.1061 - val_accuracy: 0.4378\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 28s 73ms/step - loss: 2.4093 - accuracy: 0.3724 - val_loss: 2.2109 - val_accuracy: 0.4257\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 2.3988 - accuracy: 0.3730 - val_loss: 2.1075 - val_accuracy: 0.4390\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 2.3659 - accuracy: 0.3819 - val_loss: 2.0564 - val_accuracy: 0.4509\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.3457 - accuracy: 0.3855 - val_loss: 2.1863 - val_accuracy: 0.4310\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.3031 - accuracy: 0.3949 - val_loss: 2.0075 - val_accuracy: 0.4647\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.2726 - accuracy: 0.4019 - val_loss: 1.9333 - val_accuracy: 0.4767\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.2522 - accuracy: 0.4064 - val_loss: 2.0574 - val_accuracy: 0.4611\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.2233 - accuracy: 0.4154 - val_loss: 2.0581 - val_accuracy: 0.4634\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.2013 - accuracy: 0.4188 - val_loss: 1.8179 - val_accuracy: 0.5084\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.1948 - accuracy: 0.4199 - val_loss: 2.0652 - val_accuracy: 0.4551\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 28s 73ms/step - loss: 2.1606 - accuracy: 0.4237 - val_loss: 1.8275 - val_accuracy: 0.4985\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.1601 - accuracy: 0.4274 - val_loss: 1.8336 - val_accuracy: 0.5077\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.1424 - accuracy: 0.4282 - val_loss: 1.9240 - val_accuracy: 0.4859\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.1233 - accuracy: 0.4366 - val_loss: 1.7967 - val_accuracy: 0.5106\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 2.1020 - accuracy: 0.4404 - val_loss: 1.8222 - val_accuracy: 0.5044\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 2.0972 - accuracy: 0.4419 - val_loss: 1.8232 - val_accuracy: 0.5094\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 2.0652 - accuracy: 0.4432 - val_loss: 1.8359 - val_accuracy: 0.5069\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 28s 73ms/step - loss: 2.0720 - accuracy: 0.4480 - val_loss: 1.7393 - val_accuracy: 0.5211\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 2.0228 - accuracy: 0.4594 - val_loss: 1.9189 - val_accuracy: 0.4854\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 2.0500 - accuracy: 0.4467 - val_loss: 1.7249 - val_accuracy: 0.5281\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 28s 73ms/step - loss: 2.0225 - accuracy: 0.4553 - val_loss: 1.7972 - val_accuracy: 0.5176\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 2.0163 - accuracy: 0.4575 - val_loss: 1.7735 - val_accuracy: 0.5210\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 2.0077 - accuracy: 0.4626 - val_loss: 1.7468 - val_accuracy: 0.5221\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 29s 75ms/step - loss: 1.9884 - accuracy: 0.4648 - val_loss: 1.7537 - val_accuracy: 0.5260\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 1.9869 - accuracy: 0.4684 - val_loss: 1.8638 - val_accuracy: 0.4991\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 1.9801 - accuracy: 0.4689 - val_loss: 1.8386 - val_accuracy: 0.5184\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 1.9787 - accuracy: 0.4648 - val_loss: 1.7545 - val_accuracy: 0.5202\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 1.9424 - accuracy: 0.4747 - val_loss: 1.7518 - val_accuracy: 0.5281\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 1.9374 - accuracy: 0.4742 - val_loss: 1.8094 - val_accuracy: 0.5159\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 28s 73ms/step - loss: 1.9274 - accuracy: 0.4786 - val_loss: 1.6322 - val_accuracy: 0.5527\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 1.9091 - accuracy: 0.4838 - val_loss: 1.7529 - val_accuracy: 0.5252\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 1.9279 - accuracy: 0.4798 - val_loss: 1.6472 - val_accuracy: 0.5469\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 28s 73ms/step - loss: 1.9116 - accuracy: 0.4812 - val_loss: 1.7305 - val_accuracy: 0.5357\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 1.8974 - accuracy: 0.4798 - val_loss: 1.6373 - val_accuracy: 0.5482\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 1.9188 - accuracy: 0.4776 - val_loss: 1.6377 - val_accuracy: 0.5483\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 1.8889 - accuracy: 0.4861 - val_loss: 1.6117 - val_accuracy: 0.5578\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 1.8754 - accuracy: 0.4904 - val_loss: 1.6822 - val_accuracy: 0.5366\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 1.8727 - accuracy: 0.4886 - val_loss: 1.6276 - val_accuracy: 0.5541\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 28s 73ms/step - loss: 1.8528 - accuracy: 0.5012 - val_loss: 1.6909 - val_accuracy: 0.5337\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 1.8698 - accuracy: 0.4884 - val_loss: 1.6625 - val_accuracy: 0.5420\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 1.8724 - accuracy: 0.4873 - val_loss: 1.6093 - val_accuracy: 0.5579\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 1.8609 - accuracy: 0.4946 - val_loss: 1.6049 - val_accuracy: 0.5645\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 1.8454 - accuracy: 0.4977 - val_loss: 1.6339 - val_accuracy: 0.5521\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 1.8210 - accuracy: 0.5050 - val_loss: 1.6484 - val_accuracy: 0.5507\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 1.8203 - accuracy: 0.5005 - val_loss: 1.9910 - val_accuracy: 0.5130\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 1.8265 - accuracy: 0.5030 - val_loss: 1.6229 - val_accuracy: 0.5550\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 28s 73ms/step - loss: 1.8270 - accuracy: 0.4993 - val_loss: 1.7017 - val_accuracy: 0.5433\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 28s 73ms/step - loss: 1.8199 - accuracy: 0.5023 - val_loss: 1.6167 - val_accuracy: 0.5603\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 1.8393 - accuracy: 0.5019 - val_loss: 1.7677 - val_accuracy: 0.5356\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 1.8192 - accuracy: 0.5028 - val_loss: 1.6214 - val_accuracy: 0.5524\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 1.8135 - accuracy: 0.5031 - val_loss: 1.6472 - val_accuracy: 0.5526\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 1.7866 - accuracy: 0.5139 - val_loss: 1.6609 - val_accuracy: 0.5440\n",
      "Minimum validation loss: 1.604914903640747\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model = model.fit(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                  epochs=epochs,\n",
    "                  callbacks=[early_stopping],\n",
    "                  verbose=1,\n",
    "                  validation_data=(x_test, y_test))\n",
    "\n",
    "history_df = pd.DataFrame(train_model.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RZUIDwf9Jrvq",
    "outputId": "cf1d35f5-bc3c-4c8a-b53b-40c5628a3dd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 1.6049 - accuracy: 0.5645\n",
      "Test loss: 1.604914903640747\n",
      "Test accuracy: 0.5644999742507935\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, steps=math.ceil(10000/32))\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9usKgHYeRnJ"
   },
   "source": [
    "## Cifar10\n",
    "> W celu pokazania jakości modelu, model o tej samej architekrurze co model finalny został nauczony i przetestowany na znacznie prostszym ale podobnym datasecie Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sXF8YEiS3vog",
    "outputId": "bd758ca6-33a7-46cb-a584-b9a6fc6de8b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#dataset loading CIFAR10\n",
    "(x10_train, y10_train), (x10_test, y10_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybvxc3ld3yZH"
   },
   "outputs": [],
   "source": [
    "#data shape 10\n",
    "input_shape10 = x10_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrXBvZD54Hau"
   },
   "outputs": [],
   "source": [
    "x10_train = x10_train / 255.0\n",
    "x10_test = x10_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izFQo4F2eOFv"
   },
   "source": [
    ">Tutaj inaczej niż jak przy CIFAR-100, wymiarowość zmieniona została do postacji 10 kolumn, aby dopasować się do 10 klas w tym zbiorze danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVeC5gRG4OwY"
   },
   "outputs": [],
   "source": [
    "y10_train = tf.keras.utils.to_categorical(y10_train, num_classes=10)\n",
    "y10_test = tf.keras.utils.to_categorical(y10_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_lb7ZJX4u0I"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54YMsaZYeq7p"
   },
   "source": [
    "#### Model Finalny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WuGmn7cO4zM2"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=10, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model10 = Sequential()\n",
    "model10.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                  kernel_initializer='he_normal',\n",
    "                 input_shape=input_shape10))\n",
    "model10.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "model10.add(tf.keras.layers.BatchNormalization())\n",
    "model10.add(Dropout(0.3))\n",
    "\n",
    "model10.add(Conv2D(128, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "model10.add(Conv2D(128, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "model10.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model10.add(tf.keras.layers.BatchNormalization())\n",
    "model10.add(Dropout(0.4))\n",
    "\n",
    "model10.add(Conv2D(256, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "model10.add(Conv2D(256, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "model10.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model10.add(tf.keras.layers.BatchNormalization())\n",
    "model10.add(Dropout(0.5))\n",
    "\n",
    "model10.add(Flatten())\n",
    "model10.add(Dense(1024, activation='relu'))\n",
    "model10.add(Dropout(0.4))\n",
    "model10.add(Dense(512, activation='relu'))\n",
    "model10.add(Dropout(0.3))\n",
    "model10.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXhu8fPF42MP"
   },
   "outputs": [],
   "source": [
    "model10.compile(optimizer='adam', loss= losses.CategoricalCrossentropy(from_logits=True), metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fDRJkx1F45BG",
    "outputId": "f1a01fdb-1131-4d54-918f-787af66a6c5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "391/391 [==============================] - 37s 74ms/step - loss: 2.1898 - accuracy: 0.2540 - val_loss: 1.7604 - val_accuracy: 0.3389\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 1.6348 - accuracy: 0.3966 - val_loss: 1.4160 - val_accuracy: 0.4779\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 1.4362 - accuracy: 0.4820 - val_loss: 1.7721 - val_accuracy: 0.4616\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 1.3059 - accuracy: 0.5371 - val_loss: 1.1546 - val_accuracy: 0.6072\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 1.2253 - accuracy: 0.5645 - val_loss: 0.9594 - val_accuracy: 0.6607\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 1.1587 - accuracy: 0.5926 - val_loss: 1.3107 - val_accuracy: 0.5932\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 1.1268 - accuracy: 0.6033 - val_loss: 0.9690 - val_accuracy: 0.6586\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 1.0750 - accuracy: 0.6275 - val_loss: 0.8124 - val_accuracy: 0.7152\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 1.0342 - accuracy: 0.6403 - val_loss: 1.1373 - val_accuracy: 0.6322\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 1.0020 - accuracy: 0.6546 - val_loss: 0.9332 - val_accuracy: 0.6868\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.9899 - accuracy: 0.6616 - val_loss: 0.9477 - val_accuracy: 0.6889\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.9609 - accuracy: 0.6712 - val_loss: 0.8134 - val_accuracy: 0.7274\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.9389 - accuracy: 0.6832 - val_loss: 0.8757 - val_accuracy: 0.7112\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.9318 - accuracy: 0.6873 - val_loss: 0.7315 - val_accuracy: 0.7507\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.8939 - accuracy: 0.6983 - val_loss: 0.7352 - val_accuracy: 0.7480\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 28s 70ms/step - loss: 0.8743 - accuracy: 0.7001 - val_loss: 0.8275 - val_accuracy: 0.7182\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.8639 - accuracy: 0.7067 - val_loss: 0.8159 - val_accuracy: 0.7308\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.8547 - accuracy: 0.7116 - val_loss: 0.7843 - val_accuracy: 0.7390\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 28s 70ms/step - loss: 0.8346 - accuracy: 0.7163 - val_loss: 0.8058 - val_accuracy: 0.7386\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.8292 - accuracy: 0.7213 - val_loss: 0.6707 - val_accuracy: 0.7677\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.8111 - accuracy: 0.7251 - val_loss: 0.6769 - val_accuracy: 0.7752\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 0.7870 - accuracy: 0.7329 - val_loss: 0.6712 - val_accuracy: 0.7812\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.7784 - accuracy: 0.7346 - val_loss: 0.6736 - val_accuracy: 0.7769\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.7731 - accuracy: 0.7398 - val_loss: 0.6488 - val_accuracy: 0.7854\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.7643 - accuracy: 0.7434 - val_loss: 0.6602 - val_accuracy: 0.7713\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 28s 70ms/step - loss: 0.7493 - accuracy: 0.7480 - val_loss: 0.6010 - val_accuracy: 0.7967\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 0.7341 - accuracy: 0.7505 - val_loss: 0.6000 - val_accuracy: 0.8012\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.7319 - accuracy: 0.7526 - val_loss: 0.8244 - val_accuracy: 0.7386\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.7207 - accuracy: 0.7579 - val_loss: 0.6032 - val_accuracy: 0.7978\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.7302 - accuracy: 0.7536 - val_loss: 0.6176 - val_accuracy: 0.7912\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.7105 - accuracy: 0.7603 - val_loss: 0.6009 - val_accuracy: 0.7979\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 0.6955 - accuracy: 0.7667 - val_loss: 0.6733 - val_accuracy: 0.7748\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.6839 - accuracy: 0.7655 - val_loss: 0.6238 - val_accuracy: 0.7895\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.6849 - accuracy: 0.7709 - val_loss: 0.5336 - val_accuracy: 0.8213\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 28s 70ms/step - loss: 0.6750 - accuracy: 0.7725 - val_loss: 0.6842 - val_accuracy: 0.7745\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 0.6759 - accuracy: 0.7712 - val_loss: 0.5810 - val_accuracy: 0.8067\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.6715 - accuracy: 0.7745 - val_loss: 0.5724 - val_accuracy: 0.8066\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.6534 - accuracy: 0.7821 - val_loss: 0.4800 - val_accuracy: 0.8347\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 28s 70ms/step - loss: 0.6419 - accuracy: 0.7816 - val_loss: 0.4975 - val_accuracy: 0.8330\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.6471 - accuracy: 0.7811 - val_loss: 0.5075 - val_accuracy: 0.8277\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 28s 70ms/step - loss: 0.6332 - accuracy: 0.7874 - val_loss: 0.5931 - val_accuracy: 0.8063\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.6284 - accuracy: 0.7868 - val_loss: 0.4894 - val_accuracy: 0.8350\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 0.6290 - accuracy: 0.7912 - val_loss: 0.4820 - val_accuracy: 0.8364\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.6179 - accuracy: 0.7909 - val_loss: 0.5463 - val_accuracy: 0.8165\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 28s 70ms/step - loss: 0.6178 - accuracy: 0.7905 - val_loss: 0.5652 - val_accuracy: 0.8071\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6023 - accuracy: 0.7956 - val_loss: 0.5098 - val_accuracy: 0.8318\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6149 - accuracy: 0.7947 - val_loss: 0.5188 - val_accuracy: 0.8268\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.5900 - accuracy: 0.7987 - val_loss: 0.5218 - val_accuracy: 0.8232\n",
      "Minimum validation loss: 0.4799579083919525\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model = model10.fit(datagen.flow(x10_train, y10_train, batch_size=128),\n",
    "                  epochs=epochs,\n",
    "                  callbacks=[early_stopping],\n",
    "                  verbose=1,\n",
    "                  validation_data=(x10_test, y10_test))\n",
    "\n",
    "history_df = pd.DataFrame(train_model.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wHR96PnOJSi-",
    "outputId": "41166df6-506b-4908-ddf0-dc937375ed19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4800 - accuracy: 0.8347\n",
      "Test loss: 0.4799579083919525\n",
      "Test accuracy: 0.8346999883651733\n"
     ]
    }
   ],
   "source": [
    "score = model10.evaluate(x10_test, y10_test, steps=math.ceil(10000/32))\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VHVk0tcdGA3"
   },
   "source": [
    "## Wnioski\n",
    ">Celem raportu było stworzenie modelu sieci neuronowych, który pozwoli precyzyjnie podporządkować obrazy ze zbioru CIFAR100 do odpowiadających im 100 klas. Ostateczny model powstał po wielu próbach i dzięki wyciągniętym wnioskom, odpowiednio dostosowano hiperparametry oraz wybrano funkcje aktywacji. Pierwszy zaprezentowany model pokazuje jaka poprawa nastąpiła po kalibracji modelu, wstępna trafność wynosi około 45%, co było wynikiem niezadowalającym. Po zastosowaniu funkcji: Dropuot, BatchNormalization i Maxpooling precyzja wzrosła do ponad 56%. Wydaje się to także wynikiem przeciętnym, warto jednak zwrócić uwagę, iż zbiór zawiera aż 100 klas obiektów. Aby pokazać różnicę w poziomie trudności wykorzystany model został dodatkowo wykorzystany do rozpoznania obrazów na zbiorze CIFAR10, tam jego precyzja wynosi ponad 83% co może świadczyć o dobrej jakości modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eHsnuOGdQBQ"
   },
   "source": [
    "## Bibliografia\n",
    "1. Deep Learning - Ian Goodfellow, Aaron Courville\n",
    "Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts,Tools, and Techniques to Build Intelligent Systems - Aurelien Geron Revisiting Small Batch Training for Deep Neural Networks, 2018 - Dominic Masters, Carlo Luschi.\n",
    "\n",
    "2. Canadian Institute For Advanced Research \"https://www.cs.toronto.edu/~kriz/cifar.html\", dostęp 03.2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N46OhlnldrpO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
